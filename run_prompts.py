
import os
import openai
import requests
import uuid
from datetime import datetime
from supabase import create_client, Client
import re
import json

# Set up OpenAI and Supabase
client = openai.OpenAI(api_key=os.environ['OPENAI_API_KEY'])
SUPABASE_URL = os.environ['SUPABASE_URL']
SUPABASE_KEY = os.environ['SUPABASE_KEY']
BRAVE_API_KEY = os.environ['BRAVE_API_KEY']
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

# Logging helper
def log(msg):
    print(msg, flush=True)

# Test Supabase connection
def test_supabase_connection():
    log("ğŸ”— Testing Supabase connection...")
    try:
        # Test connection by attempting to read from brands table
        response = supabase.table("brands").select("id").limit(1).execute()
        log(f"âœ… Supabase connection successful. Response: {response}")
        return True
    except Exception as e:
        log(f"âŒ Supabase connection failed: {e}")
        return False

# Get real search results from Brave Search API
def get_brave_search_results(query, count=10):
    log(f"ğŸ” Searching Brave for: '{query}'")
    
    headers = {
        "Accept": "application/json",
        "Accept-Encoding": "gzip",
        "X-Subscription-Token": BRAVE_API_KEY
    }
    
    params = {
        "q": query,
        "count": count,
        "search_lang": "en",
        "country": "US",
        "safesearch": "moderate",
        "text_decorations": "false",
        "spellcheck": "true"
    }
    
    try:
        response = requests.get(
            "https://api.search.brave.com/res/v1/web/search",
            headers=headers,
            params=params
        )
        
        log(f"ğŸ” Brave API response status: {response.status_code}")
        
        if response.status_code == 200:
            data = response.json()
            results = data.get('web', {}).get('results', [])
            log(f"ğŸ” Found {len(results)} search results from Brave")
            
            # Debug: Print first few results
            for i, result in enumerate(results[:3]):
                log(f"ğŸ” Result {i+1}: {result.get('title', 'No title')[:50]}...")
            
            return results
        else:
            log(f"âŒ Brave API error: {response.status_code} - {response.text}")
            return []
            
    except Exception as e:
        log(f"âŒ Error calling Brave API: {e}")
        return []

# Upload Google search results to database
def upload_google_results(prompt_text, brand_name, search_results):
    """Upload Google search results to the google_results table"""
    log(f"ğŸ“¤ Starting Google upload for: '{prompt_text}' - Brand: {brand_name}")
    
    if not search_results:
        log(f"âŒ No search results to upload for Google")
        return False
    
    try:
        # Check if brand appears in search results
        brand_found_position = None
        found_result = None
        
        for i, result in enumerate(search_results, 1):
            title = result.get('title', '').lower()
            description = result.get('description', '').lower()
            url = result.get('url', '').lower()
            
            log(f"ğŸ” Google check {i}: Looking for '{brand_name.lower()}' in title/desc/url")
            
            # Check if brand name appears in title, description, or URL
            if (brand_name.lower() in title or 
                brand_name.lower() in description or 
                brand_name.lower() in url):
                brand_found_position = i
                found_result = result
                log(f"âœ… Found '{brand_name}' at position {i} in Google results")
                break
        
        if not brand_found_position:
            log(f"âŒ Brand '{brand_name}' not found in Google results")
        
        # ALWAYS upload data, even if brand not found
        data = {
            "id": str(uuid.uuid4()),
            "brand_name": brand_name,
            "prompt_text": prompt_text,
            "position": brand_found_position,
            "url": found_result.get('url') if found_result else None,
            "title": found_result.get('title') if found_result else None,
            "description": found_result.get('description') if found_result else None,
            "run_date": datetime.utcnow().date().isoformat(),
            "created_at": datetime.utcnow().isoformat()
        }
        
        log(f"ğŸ“¤ Uploading Google data: {json.dumps(data, indent=2)}")
        
        res = supabase.table("google_results").insert(data).execute()
        if res.data:
            log(f"âœ… Successfully uploaded Google result - Position: {brand_found_position or 'Not Found'}")
            log(f"âœ… Google upload response data: {res.data}")
            return True
        else:
            log(f"âŒ Google upload failed - no data returned: {res}")
            return False
            
    except Exception as e:
        log(f"âŒ Google upload exception: {e}")
        import traceback
        log(f"âŒ Google traceback: {traceback.format_exc()}")
        return False

# Upload Bing search results to database
def upload_bing_results(prompt_text, brand_name, search_results):
    """Upload Bing search results to the bing_results table"""
    log(f"ğŸ“¤ Starting Bing upload for: '{prompt_text}' - Brand: {brand_name}")
    
    if not search_results:
        log(f"âŒ No search results to upload for Bing")
        return False
    
    try:
        # Check if brand appears in search results
        brand_found_position = None
        found_result = None
        
        for i, result in enumerate(search_results, 1):
            title = result.get('title', '').lower()
            description = result.get('description', '').lower()
            url = result.get('url', '').lower()
            
            log(f"ğŸ” Bing check {i}: Looking for '{brand_name.lower()}' in title/desc/url")
            
            # Check if brand name appears in title, description, or URL
            if (brand_name.lower() in title or 
                brand_name.lower() in description or 
                brand_name.lower() in url):
                brand_found_position = i
                found_result = result
                log(f"âœ… Found '{brand_name}' at position {i} in Bing results")
                break
        
        if not brand_found_position:
            log(f"âŒ Brand '{brand_name}' not found in Bing results")
        
        # ALWAYS upload data, even if brand not found
        data = {
            "id": str(uuid.uuid4()),
            "brand_name": brand_name,
            "prompt_text": prompt_text,
            "position": brand_found_position,
            "url": found_result.get('url') if found_result else None,
            "title": found_result.get('title') if found_result else None,
            "description": found_result.get('description') if found_result else None,
            "run_date": datetime.utcnow().date().isoformat(),
            "created_at": datetime.utcnow().isoformat()
        }
        
        log(f"ğŸ“¤ Uploading Bing data: {json.dumps(data, indent=2)}")
        
        res = supabase.table("bing_results").insert(data).execute()
        if res.data:
            log(f"âœ… Successfully uploaded Bing result - Position: {brand_found_position or 'Not Found'}")
            log(f"âœ… Bing upload response data: {res.data}")
            return True
        else:
            log(f"âŒ Bing upload failed - no data returned: {res}")
            return False
            
    except Exception as e:
        log(f"âŒ Bing upload exception: {e}")
        import traceback
        log(f"âŒ Bing traceback: {traceback.format_exc()}")
        return False

# Format search results for AI analysis
def format_search_results_for_ai(search_results):
    formatted_results = []
    for i, result in enumerate(search_results, 1):
        formatted_result = f"{i}. {result.get('title', 'No title')}\n"
        formatted_result += f"   URL: {result.get('url', 'No URL')}\n"
        formatted_result += f"   Description: {result.get('description', 'No description')}\n"
        formatted_results.append(formatted_result)
    
    return "\n".join(formatted_results)

# Extract position from AI response (1â€“10 only, else "Not Found")
def extract_position(response_text, target_brand):
    log(f"ğŸ” Analyzing AI response for brand '{target_brand}':")
    log(f"ğŸ” AI response excerpt: {response_text[:300]}...")
    
    lines = response_text.strip().splitlines()
    for line_num, line in enumerate(lines, 1):
        # Look for numbered list format (1., 2., etc.)
        match = re.match(r"(\d+)\.\s*(.+)", line.strip())
        if match:
            position = int(match.group(1))
            company_info = match.group(2).lower()
            
            # Check if target brand is mentioned in this ranked position
            if target_brand.lower() in company_info:
                if 1 <= position <= 10:
                    log(f"ğŸ” Brand '{target_brand}' found at position {position}")
                    return str(position)
                else:
                    log(f"ğŸ” Brand '{target_brand}' found but at position {position} (>10), marking as Not Found")
                    return "Not Found"
    
    # Check if brand is mentioned but no position found
    if target_brand.lower() in response_text.lower():
        log(f"ğŸ” Brand '{target_brand}' mentioned but no clear ranking position found")
        return "Not Found"
    
    log(f"ğŸ” Brand '{target_brand}' not found in AI ranking")
    return "Not Found"

# Evaluate a single prompt using real search data
def evaluate_prompt(prompt, brand):
    log(f"ğŸ” Starting evaluation for prompt: '{prompt}' and brand: '{brand}'")
    
    # Get real search results from Brave
    search_results = get_brave_search_results(prompt)
    
    if not search_results:
        log(f"âŒ No search results found for '{prompt}' - skipping uploads")
        return None, None
    
    log(f"ğŸ“¤ Got {len(search_results)} results, proceeding with uploads...")
    
    # Upload to Google and Bing tables (using Brave data as proxy for both)
    google_success = upload_google_results(prompt, brand, search_results)
    bing_success = upload_bing_results(prompt, brand, search_results)
    
    log(f"ğŸ“Š Upload results - Google: {'âœ… SUCCESS' if google_success else 'âŒ FAILED'}, Bing: {'âœ… SUCCESS' if bing_success else 'âŒ FAILED'}")
    
    # Format results for AI analysis
    formatted_results = format_search_results_for_ai(search_results)
    
    # Create ChatGPT-style prompt for AI analysis
    analysis_prompt = f"""Based on the search results below, please list the top companies/brands for the keyword "{prompt}". 

Here are the current search results:

{formatted_results}

Your task is to:
1. Analyze these search results
2. Rank the top companies/brands mentioned for this keyword in order of relevance and authority
3. Provide a numbered list (1-10) of the best companies for "{prompt}" based on these results
4. Focus on actual companies/brands, not just informational websites

Please respond with a clear numbered list format like:
1. Company Name - brief reason
2. Company Name - brief reason
etc.

Target brand to pay special attention to: {brand}"""

    try:
        log(f"ğŸ§  Sending request to OpenAI for AI analysis...")
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "You are an expert business analyst who ranks companies based on search results. Provide clear, numbered rankings of the top companies for any given keyword."},
                {"role": "user", "content": analysis_prompt}
            ],
            temperature=0.3,
            max_tokens=1000
        )
        result_text = response.choices[0].message.content.strip()
        position = extract_position(result_text, brand)
        log(f"ğŸ” Final AI position determined: '{position}' (type: {type(position)})")
        return result_text, position
    except Exception as e:
        log(f"âŒ Error analyzing search results for '{prompt}': {e}")
        return None, None

# Upload AI results to Supabase
def upload_result(prompt_id, result_text, position, brand, original_prompt):
    log(f"ğŸ“¤ About to upload AI result to Supabase:")
    log(f"ğŸ“¤ Position value: '{position}' (type: {type(position)})")
    
    try:
        # Convert position to determine success and brand_mentioned
        is_ranked = position != "Not Found" and position is not None
        brand_mentioned = is_ranked
        
        log(f"ğŸ“¤ is_ranked: {is_ranked}")
        log(f"ğŸ“¤ brand_mentioned: {brand_mentioned}")
        
        data = {
            "id": str(uuid.uuid4()),
            "prompt_id": prompt_id,
            "ai_result": result_text,
            "position": position,
            "brand_mentioned": brand_mentioned,
            "run_date": datetime.utcnow().date().isoformat(),
            "brand_name": brand,
            "prompt_text": original_prompt,
            "tracking_type": "ai",  # Mark as AI tracking
            "created_at": datetime.utcnow().isoformat()
        }
        
        log(f"ğŸ“¤ Final AI data being sent to Supabase: {json.dumps(data, indent=2)}")
        
        res = supabase.table("prompt_results").insert(data).execute()
        if res.data:
            log(f"âœ… Uploaded AI result for: '{original_prompt}' - Position: {position}")
            log(f"âœ… AI Supabase response: {res.data}")
            return True
        else:
            log(f"âŒ AI upload failed: {res}")
            return False
    except Exception as e:
        log(f"âŒ AI upload exception: {e}")
        import traceback
        log(f"âŒ AI traceback: {traceback.format_exc()}")
        return False

# Main process
if __name__ == "__main__":
    log(f"ğŸš€ Running @ {datetime.utcnow().isoformat()} UTC")

    # Test Supabase connection first
    if not test_supabase_connection():
        log("âŒ Cannot proceed without Supabase connection")
        exit(1)

    log("ğŸ“¦ Fetching prompts from Supabase...")
    response = supabase.table("prompts").select("id, prompt_text, brand_id").execute()

    if response.data:
        prompts = response.data
        log(f"ğŸ“¦ Found {len(prompts)} prompts")

        # Fetch brands to get brand names
        brands_response = supabase.table("brands").select("id, name").execute()
        brands_dict = {brand['id']: brand['name'] for brand in brands_response.data} if brands_response.data else {}
        log(f"ğŸ“¦ Found {len(brands_dict)} brands")

        for entry in prompts:
            prompt_id = entry['id']
            prompt_text = entry['prompt_text']
            brand_id = entry['brand_id']
            brand_name = brands_dict.get(brand_id, "Unknown Brand")

            log(f"ğŸ§  Evaluating prompt: '{prompt_text}' for brand: {brand_name}")
            result_text, position = evaluate_prompt(prompt_text, brand_name)

            if result_text:
                ai_success = upload_result(prompt_id, result_text, position, brand_name, prompt_text)
                log(f"ğŸ“Š AI upload success: {'âœ… SUCCESS' if ai_success else 'âŒ FAILED'}")
            else:
                log(f"âŒ Skipping AI upload for '{prompt_text}' - no result text")
                
            log("=" * 80)  # Separator between entries
    else:
        log(f"âŒ Failed to fetch prompts: {response}")

    log("âœ… Done.")
</lov-write>
